# -*- coding: utf-8 -*-
"""
Aplica√ß√£o Streamlit - Pipeline de An√°lise de Pept√≠deos
=======================================================
Interface web completa para an√°lise de ep√≠topos e gera√ß√£o de dossi√™s.

Autor: Engenheiro de Bioinform√°tica S√™nior
Vers√£o: 2.0.0
"""

import logging
import sys
from typing import Optional
import streamlit as st
import pandas as pd
import numpy as np
import io
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Importa m√≥dulos da src/
try:
    from src import (
        FastaProcessor,
        MHCAnalyzer,
        APIManager,
        PDFGenerator,
        ConservationAnalyzer
    )
except ImportError as e:
    st.error(f"‚ùå Erro ao importar m√≥dulos: {e}")
    st.error("Certifique-se de que todos os arquivos est√£o na pasta src/")
    st.stop()

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Pipeline de An√°lise de Pept√≠deos",
    page_icon="üß¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2C3E50;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_resource
def get_mhc_analyzer():
    """
    Carrega analisador MHC uma √∫nica vez na mem√≥ria.
    Usa @st.cache_resource para evitar recarregar modelos pesados.
    """
    logger.info("Carregando MHCAnalyzer (cacheado)")
    return MHCAnalyzer()


@st.cache_resource
def get_fasta_processor(min_length: int = 8, max_length: int = 14):
    """
    Carrega processador FASTA com par√¢metros espec√≠ficos.
    """
    return FastaProcessor(min_length=min_length, max_length=max_length)


def create_affinity_chart(df: pd.DataFrame) -> Optional[go.Figure]:
    """Cria gr√°fico de afinidade interativo."""
    if 'affinity_nm' not in df.columns or df['affinity_nm'].isna().all():
        return None
    
    df_plot = df.head(20).copy()
    df_plot = df_plot.sort_values('affinity_nm', ascending=True)
    
    fig = go.Figure()
    
    colors = ['#27AE60' if x < 50 else '#F39C12' if x < 500 else '#E74C3C' 
              for x in df_plot['affinity_nm']]
    
    fig.add_trace(go.Bar(
        x=df_plot['affinity_nm'],
        y=df_plot['peptide'],
        orientation='h',
        marker_color=colors,
        text=[f"{x:.2f} nM" for x in df_plot['affinity_nm']],
        textposition='outside',
        name='Afinidade'
    ))
    
    fig.add_vline(x=50, line_dash="dash", line_color="green", 
                  annotation_text="Limite Forte (50nM)")
    
    fig.update_layout(
        title="Top 20 Pept√≠deos por Afinidade (IC50)",
        xaxis_title="Afinidade (nM) - Menor √© Melhor",
        yaxis_title="Pept√≠deo",
        height=600,
        showlegend=False,
        template="plotly_white"
    )
    
    return fig


def main():
    """Fun√ß√£o principal da aplica√ß√£o."""
    
    # Header
    st.markdown('<p class="main-header">üß¨ Pipeline de An√°lise de Pept√≠deos</p>', 
                unsafe_allow_html=True)
    st.markdown("---")
    
    # Sidebar - Configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # Upload de arquivo
        st.subheader("üìÅ Entrada de Dados")
        uploaded_file = st.file_uploader(
            "Carregue arquivo FASTA, TSV, CSV ou Excel",
            type=['fasta', 'fa', 'faa', 'tsv', 'csv', 'txt', 'xlsx', 'xls'],
            help="Formatos suportados: FASTA, TSV, CSV, Excel"
        )
        
        # Par√¢metros de an√°lise
        st.subheader("üî¨ Par√¢metros de An√°lise")
        
        # Tipo de MHC
        mhc_type = st.radio(
            "Tipo de MHC",
            ["MHC-I", "MHC-II", "Ambos"],
            index=0,
            help="Selecione o tipo de MHC para an√°lise"
        )
        
        # Alelo HLA-I
        allele_class1_options = [
            "HLA-A*02:01", "HLA-A*24:02", "HLA-B*07:02", 
            "HLA-B*08:01", "HLA-C*07:01", "HLA-A*01:01"
        ]
        selected_allele_class1 = st.selectbox(
            "Alelo HLA-I (MHC-I)",
            allele_class1_options,
            index=0,
            disabled=(mhc_type == "MHC-II")
        )
        
        # Alelo HLA-II
        allele_class2_options = [
            "HLA-DRB1*01:01", "HLA-DRB1*03:01", "HLA-DRB1*04:01",
            "HLA-DRB1*07:01", "HLA-DRB1*11:01", "HLA-DRB1*15:01"
        ]
        selected_allele_class2 = st.selectbox(
            "Alelo HLA-II (MHC-II)",
            allele_class2_options,
            index=0,
            disabled=(mhc_type == "MHC-I")
        )
        
        # Tamanho do k-mer
        min_length = st.slider("Tamanho m√≠nimo (res√≠duos)", 8, 14, 8)
        max_length = st.slider("Tamanho m√°ximo (res√≠duos)", 8, 14, 14)
        
        # Op√ß√µes avan√ßadas
        st.subheader("üîß Op√ß√µes Avan√ßadas")
        
        use_api_enrichment = st.checkbox(
            "Enriquecer com APIs externas (IEDB/UniProt)",
            value=False,
            help="Consulta APIs externas (pode ser mais lento)"
        )
        
        include_conservation = st.checkbox(
            "An√°lise de conserva√ß√£o",
            value=False
        )
        
        max_workers = st.slider("Threads paralelas", 1, 10, 5)
        
        include_uniprot = st.checkbox("Incluir busca UniProt", value=False)
        
        # Bot√£o de processamento
        st.markdown("---")
        process_button = st.button(
            "üöÄ Processar An√°lise",
            type="primary",
            use_container_width=True
        )
    
    # √Årea principal
    if not uploaded_file and not process_button:
        st.info("üëà Por favor, carregue um arquivo e configure os par√¢metros na barra lateral.")
        return
    
    if not uploaded_file:
        st.warning("‚ö†Ô∏è Por favor, carregue um arquivo antes de processar.")
        return
    
    # Processamento
    if process_button:
        with st.spinner("üîÑ Processando an√°lise... Isso pode levar alguns minutos."):
            try:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Etapa 1: Carregamento e Valida√ß√£o
                status_text.text("üì• Carregando arquivo...")
                progress_bar.progress(10)
                
                file_bytes = uploaded_file.read()
                processor = get_fasta_processor(min_length, max_length)
                df_input = processor.load_peptides_from_bytes(file_bytes, uploaded_file.name)
                total_peptides = len(df_input)
                
                status_text.text(f"‚úÖ {total_peptides} pept√≠deos carregados. Validando...")
                progress_bar.progress(30)
                
                df_valid = processor.validate_peptides(df_input)
                valid_count = len(df_valid)
                
                status_text.text(f"‚úÖ {valid_count} pept√≠deos v√°lidos. Calculando propriedades...")
                progress_bar.progress(50)
                
                df_result = processor.add_physchem_properties(df_valid)
                progress_bar.progress(60)
                
                # Etapa 2: Predi√ß√µes MHC
                status_text.text("üß¨ Executando predi√ß√µes MHC...")
                progress_bar.progress(70)
                
                mhc_analyzer = get_mhc_analyzer()
                
                if mhc_type in ["MHC-I", "Ambos"]:
                    df_result = mhc_analyzer.predict_class1(df_result, [selected_allele_class1])
                
                if mhc_type in ["MHC-II", "Ambos"]:
                    df_result = mhc_analyzer.predict_class2(df_result, [selected_allele_class2])
                
                progress_bar.progress(75)
                
                # Etapa 3: Conserva√ß√£o (opcional)
                if include_conservation:
                    status_text.text("üî¨ Calculando conserva√ß√£o...")
                    progress_bar.progress(80)
                    conservation_analyzer = ConservationAnalyzer()
                    df_result = conservation_analyzer.add_conservation_to_dataframe(df_result)
                
                # Etapa 4: APIs (opcional)
                if use_api_enrichment:
                    status_text.text("üåê Consultando APIs externas...")
                    progress_bar.progress(85)
                    api_manager = APIManager(max_workers=max_workers, request_delay=0.2)
                    selected_allele = selected_allele_class1 if mhc_type != "MHC-II" else selected_allele_class2
                    df_result = api_manager.enrich_dataframe(
                        df_result,
                        allele=selected_allele,
                        include_uniprot=include_uniprot
                    )
                
                # Etapa 5: Scores Finais
                status_text.text("üìä Calculando scores finais...")
                progress_bar.progress(90)
                
                df_result = mhc_analyzer.calculate_final_scores(df_result)
                
                progress_bar.progress(100)
                status_text.text("‚úÖ An√°lise conclu√≠da!")
                
                # Salva no session state
                st.session_state['df_result'] = df_result
                st.session_state['total_peptides'] = total_peptides
                st.session_state['valid_peptides'] = valid_count
                st.session_state['selected_allele'] = selected_allele_class1 if mhc_type != "MHC-II" else selected_allele_class2
                st.session_state['mhc_type'] = mhc_type
                
                st.success("‚úÖ An√°lise processada com sucesso!")
                
            except Exception as e:
                logger.error(f"Erro durante processamento: {e}", exc_info=True)
                st.error(f"‚ùå Erro durante o processamento: {str(e)}")
                st.exception(e)
                return
    
    # Verifica se h√° resultados
    if 'df_result' not in st.session_state:
        return
    
    df_result = st.session_state['df_result']
    total_peptides = st.session_state.get('total_peptides', len(df_result))
    valid_peptides = st.session_state.get('valid_peptides', len(df_result))
    
    # Tabs - Visualiza√ß√£o
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Resumo", 
        "üß¨ Sequ√™ncias", 
        "üéØ An√°lise de Ep√≠topos", 
        "üìÑ Relat√≥rio Final"
    ])
    
    with tab1:
        st.header("üìä Resumo da An√°lise")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total de Pept√≠deos", total_peptides)
        with col2:
            st.metric("Pept√≠deos V√°lidos", valid_peptides)
        with col3:
            if 'affinity_nm' in df_result.columns:
                best_affinity = df_result['affinity_nm'].min()
                st.metric("Melhor Afinidade", f"{best_affinity:.2f} nM")
        with col4:
            validation_rate = (valid_peptides / total_peptides * 100) if total_peptides > 0 else 0
            st.metric("Taxa de Valida√ß√£o", f"{validation_rate:.1f}%")
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("Top 20 por Afinidade")
            affinity_chart = create_affinity_chart(df_result)
            if affinity_chart:
                st.plotly_chart(affinity_chart, use_container_width=True)
        
        with col2:
            if 'gravy' in df_result.columns and 'pI' in df_result.columns:
                scatter_chart = px.scatter(
                    df_result.head(50),
                    x='gravy',
                    y='pI',
                    size='affinity_nm' if 'affinity_nm' in df_result.columns else None,
                    color='affinity_nm' if 'affinity_nm' in df_result.columns else None,
                    hover_data=['peptide'],
                    title="Propriedades F√≠sico-Qu√≠micas"
                )
                st.plotly_chart(scatter_chart, use_container_width=True)
    
    with tab2:
        st.header("üß¨ Sequ√™ncias Analisadas")
        
        search_term = st.text_input("üîç Buscar pept√≠deo", "")
        if search_term:
            df_display = df_result[df_result['peptide'].str.contains(search_term, case=False, na=False)]
        else:
            df_display = df_result
        
        display_cols = ['peptide']
        if 'affinity_nm' in df_display.columns:
            display_cols.append('affinity_nm')
        if 'mhc_score' in df_display.columns:
            display_cols.append('mhc_score')
        
        st.dataframe(df_display[display_cols], use_container_width=True, height=600)
    
    with tab3:
        st.header("üéØ An√°lise Detalhada de Ep√≠topos")
        top10 = df_result.head(10)
        st.dataframe(top10, use_container_width=True)
    
    with tab4:
        st.header("üìÑ Relat√≥rio Final")
        
        report_name = st.text_input(
            "Nome do arquivo PDF",
            value=f"relatorio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        )
        
        if st.button("üì• Gerar e Baixar Relat√≥rio PDF", type="primary"):
            with st.spinner("Gerando relat√≥rio PDF..."):
                try:
                    pdf_generator = PDFGenerator()
                    pdf_path = pdf_generator.generate_report(
                        df_result,
                        report_name,
                        total_peptides=total_peptides,
                        include_statistics=True,
                        max_table_rows=50,
                        allele=st.session_state.get('selected_allele', selected_allele_class1)
                    )
                    
                    with open(pdf_path, "rb") as pdf_file:
                        st.download_button(
                            label="‚¨áÔ∏è Baixar Relat√≥rio PDF",
                            data=pdf_file.read(),
                            file_name=report_name,
                            mime="application/pdf"
                        )
                    
                    st.success("‚úÖ Relat√≥rio gerado com sucesso!")
                except Exception as e:
                    logger.error(f"Erro ao gerar PDF: {e}", exc_info=True)
                    st.error(f"‚ùå Erro ao gerar relat√≥rio: {str(e)}")

# Etapa 1: Carregamento e Valida√ß√£o
                status_text.text("üì• Carregando arquivo...")
                progress_bar.progress(10)
                
                file_bytes = uploaded_file.read()
                processor = get_fasta_processor(min_length, max_length)
                df_input = processor.load_peptides_from_bytes(file_bytes, uploaded_file.name)
                total_peptides = len(df_input)
                
                # --- NOVA MENSAGEM DE FEEDBACK ---
                st.info(f"üìÑ Arquivo lido: {total_peptides} sequ√™ncias brutas encontradas.")
                
                if total_peptides == 0:
                    st.error("‚ö†Ô∏è Nenhuma sequ√™ncia foi encontrada no arquivo. Verifique a formata√ß√£o.")
                    st.stop()
                # ----------------------------------

                status_text.text(f"‚úÖ {total_peptides} pept√≠deos carregados. Validando...")
                progress_bar.progress(30)
                
                df_valid = processor.validate_peptides(df_input)
                valid_count = len(df_valid)
                
                # --- NOVA MENSAGEM DE FEEDBACK ---
                if valid_count < total_peptides:
                    st.warning(f"üßπ Filtragem: {total_peptides - valid_count} sequ√™ncias removidas (inv√°lidas ou tamanho incorreto).")
                st.success(f"üß¨ Processando {valid_count} sequ√™ncias v√°lidas.")
                
                if valid_count == 0:
                    st.error("‚ö†Ô∏è Nenhuma sequ√™ncia v√°lida restou ap√≥s os filtros de tamanho/caracteres.")
                    st.stop()
           #-----------------------------
                # ... (c√≥digo anterior de carregamento) ...
                
                status_text.text(f"‚úÖ {total_peptides} pept√≠deos carregados. Validando...")
                progress_bar.progress(30)
                
                df_valid = processor.validate_peptides(df_input)
                valid_count = len(df_valid)
                
                # --- BLOCO DE SEGURAN√áA NOVO ---
                if valid_count == 0:
                    st.error(f"‚ùå Erro de Valida√ß√£o: Das {total_peptides} sequ√™ncias carregadas, 0 restaram.")
                    st.warning("Dica: Verifique se o 'Tamanho m√≠nimo' e 'M√°ximo' nos filtros (barra lateral) condizem com seus dados. Se voc√™ carregou prote√≠nas inteiras, aumente o tamanho m√°ximo para 1000 ou mais.")
                    st.stop() # PARA AQUI E N√ÉO TENTA CONTINUAR
                # -------------------------------
                
                st.success(f"üß¨ {valid_count} sequ√™ncias v√°lidas mantidas.")
                
                status_text.text(f"‚úÖ {valid_count} pept√≠deos v√°lidos. Calculando propriedades...")
                progress_bar.progress(50)
                
                # Agora √© seguro chamar, pois garantimos que n√£o est√° vazio
                df_result = processor.add_physchem_properties(df_valid)
                # ----------------------------------
                
                status_text.text(f"‚úÖ {valid_count} pept√≠deos v√°lidos. Calculando propriedades...")
                progress_bar.progress(50)
                
                # Aqui chama a fun√ß√£o que estava dando erro antes
                df_result = processor.add_physchem_properties(df_valid)
                
if __name__ == "__main__":
    main()
